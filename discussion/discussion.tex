\chapter{\label{ch:discussion}Discussion}
This project provided many opportunities for learning and growth and, now, at its conclusion, there is an opportunity to reflect on the proposed goals of the project and its subsequent execution. Firstly, the initial target of developing a comprehensive machine-learning model for rowing performance was quite ambitious. This became clear in January when a data collection system was still being developed. Furthermore, the data collection goal of minimal user input directly contravened the development of a meaningful model. Nevertheless, the project was still successful in developing a data collection system, and a data cleaning pipeline, providing analysis and visualisations to a number of athletes who kindly volunteered their training data, and an exploration of a potential machine learning approach using a more complete data set which could be used to predict, and prevent, athlete burnout and injury. This foundational work could serve as a basis for future development of an effective model. 

This chapter will discuss and evaluate the methods used for data collection, management, cleaning, analysis and visualization, as well as discuss the potential for future work, particularly in developing a machine-learning model for predicting athlete performance. Finally, a protocol will be outlined for the effective implementation of a system to develop and deploy a performance model, based on the learnings gleaned throughout this project.

\section{Data Collection}
\subsection{Evaluation}
The data collection system, based on the goals outlined at the start of the project, was successful in collecting data from a number of athletes, across four different data sources. Roughly 40 athletes were approached to provide data. Of that number, 12 athletes signed up, with around 8 consistently providing data and feedback on developments. This drop-off between the number of athletes registered for the platform and providing data was due to injuries or illness, preventing training. The data collection system was effective in providing a user-friendly platform for athletes to provide data with the help of the data provider's APIs. In total, since athlete recruitment was completed at the end of January, roughly 500 activities were ingested through the data collection pipeline. This number was lower than expected due to a recent, and poorly documented change by Strava in how developer apps are handled. This meant that roughly 6 weeks of training data for all but one user were not shared with the application, as a result, a number of user data sets were somewhat incomplete and there was not enough time to fully remedy this issue by backfilling athlete data. Analysis for these users was supported by data provided from Concept2, Polar, and, in the last 4 weeks, Garmin. The researcher's data set was preserved and used for developing the analysis and visualisation steps of the project.

\subsection{Discussion}
The data collection approach, while effective in minimising the effort of individual athletes, made the development of any kind of performance model difficult. The advertised automation of data collection made it easier to recruit athletes, both due to the minimal effort required to participate in the project and because of the clear security by obfuscation for competitors. This did, unfortunately, result in a dataset which was not as complete as it could have been. The lack of heart rate data for many sessions, and the lack of detail when recording strength sessions, limited the analysis which could be performed. In particular, the lack of heart rate data made it difficult to classify sessions as an endurance or interval session and also to calculate training impulse. For further advancement of this research, a more involved group of participants is required. Athletes who are willing to dedicate the time to provide feedback for sessions, and ensure their training logs are complete, make it easier to develop a model which can be used to predict performance. These individuals perhaps facilitate the low-effort data collection and analysis approach this project strove for. 

There were also a number of different training plans being executed by participants, which made it difficult to develop a model which could be used to predict performance. A more consistent training plan, or a more detailed analysis of the training plans being executed, would be necessary to develop a model which could be used to predict performance. If it were possible to onboard an entire squad or have participants commit to completing a specific training session each week, there would be a clear metric for improvements, or decline, in fitness and therefore an anchor by which to compare an athlete's performance. This will be further discussed in the final section of this chapter, \autoref{sec:model-devel-prot}.

The data collection method developed throughout this project was successful in providing an easy, and secure, way for athletes to provide training data. However, the data collected was not as complete as it could have been,  and this limited the analysis and model development which could be performed. This is an easy opportunity for future work, introducing session matching and a more detailed onboarding and feedback process, could help to ensure the data collected is more complete and useful for analysis. This also introduces the opportunity to develop daily monitoring surveys for athletes to complete to give a more comprehensive picture of their training, recovery, and general well-being, which is beneficial for more effective analysis.

There is indeed an opportunity for further exploration, particularly in the integrated tracking and management of athletes. Specifically, a system could be developed that benefits both coaches and athletes by providing useful data and feedback without overwhelming them. Originally, the emphasis on data collection was not prioritized in this project. However, there is a clear direction for future work to be explored on how technology can support training and athlete management.

\section{\label{sec:data-anyl-diss}Data Analysis and Visualisation}
\subsection{Evaluation}
The data analysis and visualisation step of this project was successful in providing easy-to-read and digest feedback to rowers on their training. First, the data cleaning step effectively cleaned and transformed data from multiple data sources and formats into a concise, uniform, format allowing more efficient analysis and visualization. Next during the analysis step, data was analysed to provide appropriate and useful feedback and insights on training habits. This analysis was guided by metrics typically used by rowers to define a successful training week, These included, reducing the amount of time and effort needed for rowers to understand their training, allowing rowers to identify trends in training behaviours, and easily identifying minor improvements to help motivate future training. Finally, the visualisation step successfully provided rowers with a way to understand the analysis graphically. The presentation of this information was particularly important to provide athletes with an at-a-glance overview of their training outcomes and habits, and the generation of visualisations was largely successful in completing this objective. This approach to presentation, allowed rowers to quickly identify trends in their training and make adjustments as necessary.

Each of these sub-steps was developed in a way that allows them to be dynamically called through serverless functions, allowing them to be run automatically when new training events were ingested by the data collection pipeline.

\subsection{Discussion}
The data analysis and visualisation portion of this project was the most straightforward part of the entire project. This was made possible due to a variety of reasons. First, the data cleaning pipeline was developed to transform data into a standard format, which made analysis and visualisation significantly easier. Second, the analysis and visualisation steps were developed to provide feedback on the most basic metrics which rowers use to define a successful training week. This meant that there was no minimum amount of data required in order to begin to explore potential analyses. Furthermore, due to the researcher's background in rowing, the metrics used to define a successful training week were already well understood and the approach to developing an analytics pipeline had already been considered before the commencement of this stage of the project. Finally, inspiration for visualisations was drawn from the work of other researchers in the field of sports science, particularly in the field of rowing, which made it easier to develop visualisations which would be beneficial to rowers.

The primary limitation of the data analysis and visualisation step was the lack of data available for analysis. Although analysis of the data available was largely successful, the lack of live heart rate data in many cases made it difficult to calculate training impulse and provide more detailed feedback on training sessions. This is a clear area for future work, and the development of a more complete data collection system, as discussed in the previous section, would help to alleviate this issue. Additionally, the lack of contextual data, such as a rower's injury or illness status, made it difficult to provide feedback on why a rower may have missed a session, or why they may have performed poorly in a session. This is another area for future work, and the development of a daily monitoring survey, as discussed in the previous section, would help to provide this context. 

One of the target analyses where this project fell short was comparing "like" sessions. For example, comparing steady-state (endurance) sessions over the course of a season. These endurance sessions may be of varying distance and target intensity. Some athletes may target a session as a UT1 (higher intensity, typically lower volume) rather than a UT2 (lower intensity, typically higher volume) session. Without the additional context of the session, provided by the user through a note or an RPE rating, it is very difficult to identify the exact type of session, making matching and comparison of these sessions impossible. With adjustments to the data collection pipeline, this would be possible, and allow athletes to more easily identify trends in their training, and make adjustments as necessary.

A number of visualisations were generated for the project as well. As described in \autoref{sec:data-viz}, the visualisations were first developed using a Jupyter notebook to more interactively work with the data. The content of the Jupyter notebooks was then condensed to produce the pipeline that was used to generate the appropriate datasets for use on the frontend. Unfortunately, converting the graphs and visualisations developed using Python into a format that could be easily displayed on the frontend was not as straightforward as initially thought. This was due to the limitations of the Plotly library, which was used to generate the visualisations. The documentation for the library was quite sparse, and a huge amount of effort was spent to ensure that data was reformatted correctly and styling was applied appropriately. In the end, three of the four visualisations were implemented in the frontend, with the modality duration and distance charts not being implemented due to issues with styling. This is a clear point for future work, and could likely be a full project in itself. Exploring how athletes interact with data, and what visualisations are most useful to them, could provide a wealth of information for future development of a data analysis and visualisation pipeline.

\section{Machine Learning}
\subsection{Evaluation}
\subsection{Discussion}

\section{\label{sec:model-devel-prot}An Ideal Protocol to Develop an Effective Model}
In order to successfully develop an effective performance model, a number of steps need to be taken. The following protocol outlines the steps which could be taken to develop, validate, and leverage a performance model which can be used to predict, and prevent, athlete burnout and injury. This protocol is based on the learnings from this project, and the research conducted throughout the project.

\subsection{\label{sub:ideal-onboard}Squad Onboarding}
Based on the difficulty in recruiting participants described in \nameref{ch:data-collect-mng}, collecting long-term training and recovery data from a large number of athletes necessitates participation from all members of senior level squads starting with senior leadership. Approaching coaches and club administrators means that assurances can be provided with regards to data protection and privacy, ensuring squad training is not leaked to other competitors, and establishes trust which can trickle down to each athlete. With this consideration, the number of eligible squads for a partnership is limited to university squads, high-performance groups in open clubs, or national teams. These squads have athletes training nearly year-round following a strict training plan. Furthermore, any squad which is onboarded needs to have complete buy-in from the coaching staff and athletes. This is necessary to ensure that all athletes are providing data, that the data is complete and accurate, and allow collaboration between the research team and the coaching staff to develop a training plan and the necessary procedures to develop a training plan. A strong relationship between the research team and the partner squad will allow for more frequent and effective iterations of athlete and coach dashboards and apps, analytics and statistics collected, generated and presented, and, if all progresses as anticipated, models for performance prediction, injury prevention, and more.

Once a squad has been identified and onboarded, each rower should complete a series of physiological tests, this will include lactate and $\textnormal{VO}_2$ max tests (much like what is described in \autoref{sub:training_principles}), strength tests such as the maximum deadlift and bench press, power tests such as a countermovement jump, resting metabolic rate test, and body composition tests. This will provide rowers with more accurate zones to train in, based on both heart rate and wattage, and provide context for a rower's physiology. These tests should be completed at least once per season where possible. Sub-maximal versions of the tests can be completed to dial in steady-state training zones as each season progresses or when recovering from illness or injury.

Squad onboarding will also include registering all coaches and rowers to an online system. Through this system, coaches will be provided an overview of their athlete's training adherence, recovery metrics, and general well-being, with tools to generate or adapt training programs, build crews for on-the-water sessions and otherwise manage their squads. Rowers will be able to see their scheduled sessions, with suggestions for personalisation based on their recovery and wellbeing metrics, and track their training and wellbeing through the platform. These features need to be implemented to both encourage engagement from athletes and coaches, by providing useful tools to track, manage, and analyse training, and also collect as much data as possible for machine learning model training. The potential analyses available as a result of collecting and collating each of these metrics can further support improvements in training behaviour, crew selection, and more. As has already been extensively discussed, providing a potential model with as much training data, and context, as possible gives the model the best chance for success in predicting performance and potential injuries, illness, or overtraining, encouraging consistent and productive training. 

\subsection{\label{sub:ideal-data-collection}Data Collection}
With a squad onboarded and initial rower data collected, the next step is to develop a data collection system. There are two main parts to consider for this system: recovery and wellness tracking, and training tracking.

\subsubsection{Recovery and wellness tracking}
Every morning athletes should complete a monitoring questionnaire, this questionnaire will include questions about sleep quality, sleep duration, muscle soreness, fatigue, stress, and mood. This questionnaire can be supported by data from wearables such as a Whoop, Oura ring, or smartwatch. These devices provide heart rate metrics (resting heart rate and heart rate variability) which can be analysed to determine recovery and readiness to train. Rowers can also note if they are unfit to train due to illness or injury. Providing this context is crucial for explaining gaps in training data when in the analysis step.

An additional metric to track could be nutrition, which can also be built into the system. A nutrition tracking system would need to track what food was eaten, how much food was consumed, and at what time. This data can be used to determine if an athlete is eating enough to support their training, and if they are eating the right foods to support their training.

\subsubsection{Training tracking}
While automated tracking and analysis of sessions would be an ideal scenario for many athletes, to effectively train a model, it is important to provide context for sessions which have been completed. An ideal training tracking solution would leverage session data provided by APIs from Concept2, Strava, Garmin, and Polar, and provide a simple interface for athletes to provide feedback on their sessions. Through the online platform, rowers would provide feedback on sessions, including how they felt during the session, how they felt after the session, and any other notes they might have. If athletes have augmented a prescribed session for any reason, this can be noted as well and feedback can be relayed to the coach. This feedback is essential for developing a model which can be used to predict performance, and identify burnout to prevent injury and illness.

Strength sessions can also be prescribed by the coaches platform, then tracked through the rower platform. By logging lifts used, the number of reps and sets completed, and tonnage moved, a coach can track the progress of their athletes, and provide feedback on their strength training. This will also provide context for the strain experienced during strength sessions, and provide a more complete picture of the training load experienced by an athlete each week.

\subsection{Analysis and Visualisation}
With data collected from a squad, the next step is to develop a data cleaning pipeline, and analysis and visualisation tools. The data cleaning pipeline can be iterated from the one developed for this project. Given the increased athlete feedback, session classification will be much more straightforward, allowing for more effective analysis. With a more complete dataset of heart rate and RPE data, alongside more detailed strength session information, the analysis and visualisation tools can be developed to provide more effective feedback to athletes and coaches. Additionally, due to the added recovery data recorded, athletes and coaches can explore the impact of different session intensity, duration, and modality on recovery and wellbeing metrics and adjust squad or personal training as a result that feedback. For example, at the start of the season, an athlete may have lost fitness as a result of time off. Within six weeks they may see a decrease in resting heart rate as a result of being trained again. Conversely, if a trained athlete begins to see their resting heart rate trend upwards, this could be an indicator of overtraining or illness and the need for a rest period. This basic feedback can be used to adjust training plans and prevent burnout and injury.

Algorithms can also be developed to suggest different training sessions based on the feedback provided by athletes. For example, if an athlete is feeling fatigued, a session with a lower intensity can be suggested. If an athlete is feeling good, a session with a higher intensity can be suggested. These suggestions can be generated as a result of morning monitoring results. Additionally, if a coach wants to maintain a certain training load, sessions can be suggested with options to account time constraints or perceived intensity.

\subsection{Model Development and Validation}
With a complete dataset, and effective analysis and visualisation tools, the next step is to develop a performance model. There will be several iterations of models. The first, and likely easiest, to develop would be a model to identify injury or overtraining. Leveraging the methods described in \autoref{ch:ml} in replicating the prediction or running injuries \cite{Lovdal2021}, a similar approach can be applied to rowing training. Ideally, considering the volume of training and recovery data collected, a more effective model can be developed. This can be used to help prevent injury and illness and provide feedback to athletes and coaches on how to adjust training plans to prevent burnout.

Next, to develop the holy grail: a model for rower performance. This model will be developed iteratively, with feedback from athletes and coaches. The standard weekly training session, outlined in \autoref{sub:ideal-onboard} can be analysed for changes in fitness, based on heart rate and wattage metrics. With these reference points for athlete performance, a model can be trained to predict performance based on the training load experienced by an athlete. With enough training and recovery data, this can then be used to build training plans for an entire macro-cycle and applied to individual athletes based on their performances each season. 

Based on the success of this model, a model for crew performance can be developed. This model will be based on the performance of individual athletes, and how they perform in a crew. This model can be used to build crews for on-the-water sessions, and provide feedback to coaches on how to adjust crews to improve performance. This model will be developed iteratively, with feedback from athletes and coaches, and will be based on the performance of individual athletes in a crew, and how they perform in different crew combinations.

\subsection{The Potential}
Assuming the success of this approach over the course of 5-10 years, a truly data driven approach for coaching and training can help a squad find success and look to optimise every part of training and recovery. The only limitation to success is how much data is available. With progress in the development of hardware to track on-the-water power, and power application, and the development of a more complete data collection system, the potential impact is significant. Athlete development and training can be tuned to prevent injury and illness, which is one of the biggest hindrances for athletes in their pursuit of success. Furthermore, crew selection can be made more data-driven and transparent, identifying the most physiologically capable athletes, and the most effective crew combinations. This approach can then be applied to other endurance sports, like cycling and running very easily. With additional adaptation and research to quantify training load, applications in field and combat sports are also possible.

The potential for further research and development in applying machine learning to sports and human performance is vast and exciting. Developing and providing these tools can free up time and energy for coaches and athletes to allow them to engage with and enjoy their sports more. This project has only scratched the surface of what is possible, and with the right approach, and the right data, the potential for success is limitless.

% the end of the section (this is only here for when I collapse the section in my editor)